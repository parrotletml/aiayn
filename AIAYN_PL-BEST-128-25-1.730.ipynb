{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8817a37-1ed8-477a-b0b5-5caa4c54de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b01decc-fdc5-4122-9264-2910ce339b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65658bcf-4a98-4c38-9b7b-c9f1bb54bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c55330-a789-4bc3-9e8e-ede3b86cc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !black ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4620a33a-fbf1-43b0-940c-7339d4afcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8e422b-eef8-467f-ba24-27b873ba77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall ipywidgets -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6faa22-0f92-437f-b821-2336b1d3e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"TORCH_CPP_LOG_LEVEL\"] = \"INFO\"\n",
    "# os.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# The GPU id to use, \"0\" to  \"7\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca7b75a-77d2-4991-92f4-bba590e95d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch=2.0.1+cu117, Lightening=2.0.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "print(f\"Torch={torch.__version__}, Lightening={pl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4bafbe2-3ef2-41ce-a282-8a1831af9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrotletml.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1b7f2a1-d321-4f7d-b535-99e42bc11812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 150\n",
      "Max length of target sentence: 159\n"
     ]
    }
   ],
   "source": [
    "from parrotletml.datamodule import BilingualDataModule\n",
    "\n",
    "data_module = BilingualDataModule(\n",
    "    dataset_path=config.dataset_path,\n",
    "    src_lang=config.lang_src,\n",
    "    tgt_lang=config.lang_tgt,\n",
    "    seq_len=config.seq_len,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=config.pin_memory,\n",
    "    tokenizer_file=config.tokenizer_file,\n",
    ")\n",
    "\n",
    "# data_module.prepare_data()\n",
    "\n",
    "# data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54920e09-9220-426a-b74b-5a1b78fcbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrotletml.bilingualmodule import BilingualModule\n",
    "\n",
    "model = BilingualModule(\n",
    "    tokenizer_src=data_module.tokenizer_src,\n",
    "    tokenizer_tgt=data_module.tokenizer_tgt,\n",
    "    seq_len=config.seq_len,\n",
    "    d_model=config.d_model,\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    "    eps=config.eps,\n",
    "    label_smoothing=config.label_smoothing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f8972c-e926-4979-b078-a57d968e4e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "INFO:pytorch_lightning.utilities.rank_zero:Loading `train_dataloader` to estimate number of stepping batches.\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | bimodel  | Transformer      | 56.3 M\n",
      "1 | criteria | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "56.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "56.3 M    Total params\n",
      "225.350   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 849/849 [04:48<00:00,  2.95it/s, v_num=66, train_loss_step=4.870]\n",
      "Epoch 1: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=3.950, val_cer=0.597, val_wer=0.923, val_bleu=0.000, train_loss_epoch=5.800]\n",
      "Epoch 2: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=3.440, val_cer=0.540, val_wer=0.731, val_bleu=0.000, train_loss_epoch=4.490]\n",
      "Epoch 3: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=3.120, val_cer=0.604, val_wer=0.808, val_bleu=0.000, train_loss_epoch=3.850]\n",
      "Epoch 4: 100%|██████████| 849/849 [04:48<00:00,  2.95it/s, v_num=66, train_loss_step=2.910, val_cer=0.561, val_wer=0.769, val_bleu=0.000, train_loss_epoch=3.520]\n",
      "Epoch 5: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=2.660, val_cer=0.568, val_wer=0.885, val_bleu=0.000, train_loss_epoch=3.320]\n",
      "Epoch 6: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=2.460, val_cer=0.597, val_wer=0.962, val_bleu=0.000, train_loss_epoch=3.140]\n",
      "Epoch 7: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=2.300, val_cer=0.576, val_wer=0.923, val_bleu=0.000, train_loss_epoch=2.950]\n",
      "Epoch 8: 100%|██████████| 849/849 [04:48<00:00,  2.95it/s, v_num=66, train_loss_step=2.180, val_cer=0.612, val_wer=0.962, val_bleu=0.000, train_loss_epoch=2.800]\n",
      "Epoch 9: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=2.070, val_cer=0.612, val_wer=0.962, val_bleu=0.000, train_loss_epoch=2.670]\n",
      "Epoch 10: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=2.010, val_cer=0.612, val_wer=0.885, val_bleu=0.000, train_loss_epoch=2.550]\n",
      "Epoch 11: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.950, val_cer=0.576, val_wer=0.885, val_bleu=0.000, train_loss_epoch=2.450]\n",
      "Epoch 12: 100%|██████████| 849/849 [04:48<00:00,  2.95it/s, v_num=66, train_loss_step=1.880, val_cer=0.576, val_wer=0.923, val_bleu=0.000, train_loss_epoch=2.360]\n",
      "Epoch 13: 100%|██████████| 849/849 [04:48<00:00,  2.94it/s, v_num=66, train_loss_step=1.840, val_cer=0.597, val_wer=0.923, val_bleu=0.000, train_loss_epoch=2.270]\n",
      "Epoch 14: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.790, val_cer=0.655, val_wer=1.040, val_bleu=0.000, train_loss_epoch=2.190]\n",
      "Epoch 15: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.760, val_cer=0.662, val_wer=1.000, val_bleu=0.000, train_loss_epoch=2.120]\n",
      "Epoch 16: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.740, val_cer=0.691, val_wer=1.080, val_bleu=0.000, train_loss_epoch=2.060]\n",
      "Epoch 17: 100%|██████████| 849/849 [04:48<00:00,  2.94it/s, v_num=66, train_loss_step=1.720, val_cer=0.676, val_wer=1.080, val_bleu=0.000, train_loss_epoch=2.010]\n",
      "Epoch 18: 100%|██████████| 849/849 [04:47<00:00,  2.96it/s, v_num=66, train_loss_step=1.700, val_cer=0.640, val_wer=0.962, val_bleu=0.000, train_loss_epoch=1.960]\n",
      "Epoch 19: 100%|██████████| 849/849 [04:46<00:00,  2.96it/s, v_num=66, train_loss_step=1.670, val_cer=0.619, val_wer=0.923, val_bleu=0.000, train_loss_epoch=1.910]\n",
      "Epoch 20: 100%|██████████| 849/849 [04:47<00:00,  2.96it/s, v_num=66, train_loss_step=1.640, val_cer=0.561, val_wer=0.808, val_bleu=0.000, train_loss_epoch=1.870]\n",
      "Epoch 21: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.620, val_cer=0.583, val_wer=0.846, val_bleu=0.000, train_loss_epoch=1.830]\n",
      "Epoch 22: 100%|██████████| 849/849 [04:51<00:00,  2.91it/s, v_num=66, train_loss_step=1.600, val_cer=0.640, val_wer=0.962, val_bleu=0.000, train_loss_epoch=1.800]\n",
      "Epoch 23: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.600, val_cer=0.640, val_wer=0.962, val_bleu=0.000, train_loss_epoch=1.770]\n",
      "Epoch 24: 100%|██████████| 849/849 [04:47<00:00,  2.95it/s, v_num=66, train_loss_step=1.580, val_cer=0.619, val_wer=0.923, val_bleu=0.000, train_loss_epoch=1.750]\n",
      "Epoch 24: 100%|██████████| 849/849 [04:48<00:00,  2.94it/s, v_num=66, train_loss_step=1.580, val_cer=0.640, val_wer=0.962, val_bleu=0.000, train_loss_epoch=1.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 849/849 [04:54<00:00,  2.88it/s, v_num=66, train_loss_step=1.580, val_cer=0.640, val_wer=0.962, val_bleu=0.000, train_loss_epoch=1.730]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pytorch_lightning.callbacks import (\n",
    "    TQDMProgressBar,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelPruning,\n",
    "    EarlyStopping,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "\n",
    "\n",
    "class MyProgressBar(TQDMProgressBar):\n",
    "    def init_validation_tqdm(self):\n",
    "        bar = super().init_validation_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    def init_predict_tqdm(self):\n",
    "        bar = super().init_predict_tqdm()\n",
    "        if not sys.stdout.isatty():\n",
    "            bar.disable = True\n",
    "        return bar\n",
    "\n",
    "    # def init_test_tqdm(self):\n",
    "    #     bar = super().init_test_tqdm()\n",
    "    #     if not sys.stdout.isatty():\n",
    "    #         bar.disable = True\n",
    "    #     return bar\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"aiayn\")\n",
    "\n",
    "# training\n",
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[\n",
    "        MyProgressBar(refresh_rate=1),\n",
    "        LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"ckpt_logs/aiayn\",\n",
    "            save_top_k=3,\n",
    "            monitor=\"train_loss\",\n",
    "            mode=\"min\",\n",
    "            filename=\"model-{epoch:02d}-{train_loss:4f}\",\n",
    "            save_last=True,\n",
    "        ),\n",
    "        # ModelPruning(\n",
    "        #     pruning_fn=\"l1_unstructured\",\n",
    "        #     amount=0.1,\n",
    "        #     use_global_unstructured=True,\n",
    "        # ),\n",
    "        EarlyStopping(monitor=\"train_loss\", mode=\"min\", stopping_threshold=1.5),\n",
    "    ],\n",
    "    logger=logger,\n",
    "    precision=\"16-mixed\",\n",
    "    accelerator=\"gpu\",\n",
    "    devices=\"auto\",\n",
    "    # strategy=\"ddp_notebook\",\n",
    "    check_val_every_n_epoch=1,\n",
    "    # limit_train_batches=5,\n",
    "    limit_val_batches=2,\n",
    "    # limit_test_batches=1,\n",
    "    max_epochs=config.num_epochs,\n",
    "    # max_epochs=1,\n",
    "    # profiler=PyTorchProfiler(),\n",
    ")\n",
    "\n",
    "# Uncomment the following line to train the model\n",
    "trainer.fit(\n",
    "    model,\n",
    "    # train_dataloaders=data_module.train_dataloader(),\n",
    "    # val_dataloaders=data_module.val_dataloader(),\n",
    "    datamodule=data_module,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a47aa0-da98-450d-a5ec-2b5ceb88a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session14/ckpt_logs/aiayn/last-v32.ckpt\n",
    "# session14/tb_logs/aiayn/version_66"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eraenv",
   "language": "python",
   "name": "eraenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
